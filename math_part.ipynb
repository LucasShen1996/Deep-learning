{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3dc4a6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: Theory and Knowledge Questions</span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 30 points]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121bef9",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.1**</span> **Activation function plays an important role in modern Deep NNs. For each of the activation function below, state its output range and find its derivative (show your steps)**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span> Sigmoid: $\\sigma(x) = \\frac{1}{1+\\text{exp}{(-x)}}$ \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(b)**</span> Tanh: $\\sigma(x) = \\frac{\\exp(x) - \\exp{(-x)}}{\\exp(x) + \\exp{(-x)}}= \\frac{1-\\exp(-2x)}{1+\\exp(-2x)}$\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c79aa",
   "metadata": {},
   "source": [
    "(a)$\\sigma(x) = \\frac{1}{1+\\text{exp}{(-x)}}$ R is Real number set$x\\in R $ it easy to know $exp(-x)>0$ so $1+\\text{exp}{(-x)}>1 $ \n",
    "So the output range of sigmoid is $0<\\sigma(x) <1$\n",
    "\n",
    "${d \\over dx}{1 \\over 1+exp(-x)} = {d \\over dx}{1+exp(-x)}^{-1}$ base on the chain rule ${d \\over dx}{1 \\over 1+exp(-x)} = {d \\over dx}{1+exp(-x)}^{-1} = {-exp(-x) \\over (1+exp(-x))^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8436833",
   "metadata": {},
   "source": [
    "(b)$\\sigma(x) = \\frac{\\exp(x) - \\exp{(-x)}}{\\exp(x) + \\exp{(-x)}}= \\frac{1-\\exp(-2x)}{1+\\exp(-2x)}$\n",
    "\n",
    "Inverse function of Tanh is $x = -{ln({1-\\sigma(x) \\over 1+\\sigma(x)}) \\over 2}$\n",
    "and it is easy to know ${1-\\sigma(x) \\over 1+\\sigma(x)} >0$ So $1-\\sigma(x) >0 and 1+\\sigma(x) > 0$\n",
    "\n",
    "So the range is $-1<\\sigma(x)<1$\n",
    "\n",
    "\n",
    "${d \\over dx}\\frac{1-\\exp(-2x)}{1+\\exp(-2x)} = \\frac{\\frac{d}{dx}\\left(1-e^{-2x}\\right)\\left(1+e^{-2x}\\right)-\\frac{d}{dx}\\left(1+e^{-2x}\\right)\\left(1-e^{-2x}\\right)}{\\left(1+e^{-2x}\\right)^2} = =\\frac{2e^{-2x}\\left(1+e^{-2x}\\right)-\\left(-2e^{-2x}\\right)\\left(1-e^{-2x}\\right)}{\\left(1+e^{-2x}\\right)^2} = \\frac{4e^{-2x}}{\\left(1+e^{-2x}\\right)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f910cbf",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.2**</span> **Softmax activation aims to transform discriminative values to prediction probabilities. Consider a classification task with $M=4$ classes and a data example $x$ with a ground-truth label $y=2$. Assume that at the output layer of a feed-forward neural network, we obtain the logits $h^{L}=[2,-1,5,0]$.**\n",
    "<span style=\"color:red\">**(a)**</span>  What is the corresonding prediction probabilities $p(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> \n",
    "\n",
    "<span style=\"color:red\">**(b)**</span>  What is the cross-entropy loss caused by the feed-forward neural network at $(x,y)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div> \n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca23d67e",
   "metadata": {},
   "source": [
    "(a) $ùëù = softmax(‚Ñé) ‚âî\\Bigg[ {exp(h_m) \\over {\\sum_{i=1}^M exp(h_i)}} \\Bigg]_m^M$\n",
    "\n",
    "\n",
    "$p_1 = {exp(2) \\over exp(2)+exp(-1)+exp(5)+exp(0)} = 0.04701311732190172$\n",
    "$p_2 = {exp(-1) \\over exp(2)+exp(-1)+exp(5)+exp(0)} = 0.0023406452862919295$\n",
    "$p_3 = {exp(5) \\over exp(2)+exp(-1)+exp(5)+exp(0)} = 0.9442837038432107$\n",
    "$p_4 = {exp(0) \\over exp(2)+exp(-1)+exp(5)+exp(0)} = 0.006362533548595672$\n",
    "$p = [0.04701311732190172,0.0023406452862919295,0.9442837038432107,0.006362533548595672]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b2bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04701311732190172 0.0023406452862919295 0.9442837038432107 0.006362533548595672\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "p1 = np.exp(2)/(np.exp(2)+np.exp(-1)+np.exp(5)+np.exp(0))\n",
    "p2 = np.exp(-1)/(np.exp(2)+np.exp(-1)+np.exp(5)+np.exp(0))\n",
    "p3 = np.exp(5)/(np.exp(2)+np.exp(-1)+np.exp(5)+np.exp(0))\n",
    "p4 = np.exp(0)/(np.exp(2)+np.exp(-1)+np.exp(5)+np.exp(0))\n",
    "print(p1,p2,p3,p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b912a75",
   "metadata": {},
   "source": [
    "(b)$l(y,p) = CE(1_y,p) = -log(p_y)$\n",
    "\n",
    "$CE([0,0,1,0],[0.04701311732190172,0.0023406452862919295,0.9442837038432107,0.006362533548595672]) = -log(0.9442837038432107) = 0.05732862425563766$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e72b8",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.3**</span> **Linear operation and element-wise activation are two building-blocks for conducting a layer in a feedforward neural network.**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span> Assume that hidden layer $1$ has value $h^1(x)= \\left[\\begin{array}{ccc}\n",
    "1.5 & 2.0 \\end{array}\\right]^T$ and the weight matrix and bias at the second layer are:\n",
    "- $W^{2}=\\left[\\begin{array}{cc}\n",
    "-1 & -1\\\\\n",
    "-1 & 1\\\\\n",
    "-1 & 0\n",
    "\\end{array}\\right]$.\n",
    "What is the value of the hidden layer $\\bar{h}^{2}(x)$ after applying *the linear operation* with the matrix $W^2$ and the bias $b^2$ over $h^1$.\n",
    "\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div> \n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(b)**</span> Assume that we apply *the ReLU activation function* at the second layer. What is the value of the hidden layer $h^2(x)$ after we apply the activation function?\n",
    "\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div> \n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dd3c4",
   "metadata": {},
   "source": [
    "(a) $\\bar{h}^{2}(x) = W^2h^1+b^2 = \\left[\\begin{array}{cc}-1 & -1\\\\-1 & 1\\\\-1 & 0 \\end{array}\\right] \\left[\\begin{array}{c}1.5 \\\\2.0 \\end{array}\\right] + \\left[\\begin{array}{c}0 \\\\0 \\end{array}\\right] = \\left[\\begin{array}{c}-3.5\\\\0.5\\\\1.5 \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ebc0",
   "metadata": {},
   "source": [
    "(b) $h^2 = Relu(\\bar{h}^{2}(x)) =  \\left[\\begin{array}{c}0\\\\0.5\\\\1.5 \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6317a7d",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 1.4**</span> **Assume that we are conducting a multilayered feedforward neural network for a regression problem to predict to real-valued $y_1, y_2$, and $y_3$. The architecture of this network ($3 (Input)\\rightarrow4(ReLU)\\rightarrow 3(Output)$) is shown in the following figure**:\n",
    "\n",
    "\n",
    "<img src=\"Figures/FeedforwardNN.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "We now feed a feature vector $x=\\left[\\begin{array}{ccc}\n",
    "1.2 & -1 & 2\\end{array}\\right]^{T}$ with ground-truth label $y=\\left[\\begin{array}{ccc} 1.5 & -1 & 2\\end{array}\\right]^{T}$ to the above network. \n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the value of $\\bar{h}^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(b)**</span>  What is the value of $h^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(c)**</span>  What is the predicted value $\\hat{y}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(d)**</span>  Suppose that we use the L2 loss. What is the value of the L2 loss $l$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1.5 points]</span></div>\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(e)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{2}},\\frac{\\partial l}{\\partial W^{2}}$, and $\\frac{\\partial l}{\\partial b^{2}}$? \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[5 points]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(f)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{1}}, \\frac{\\partial l}{\\partial \\bar{h}^{1}},\\frac{\\partial l}{\\partial W^{1}}$, and $\\frac{\\partial l}{\\partial b^{1}}$? \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[5 points]</span></div>\n",
    "\n",
    "**SGD update**\n",
    "\n",
    "<span style=\"color:red\">**(g)**</span> Assume that we use SGD with learning rate $\\eta=0.01$ to update the model parameters. What are the values of $W^2, b^2$ and $W^1, b^1$ after updating?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[4 points]</span></div>\n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a3d8a",
   "metadata": {},
   "source": [
    "(a) $\\bar{h}^{1}(x) = W^1x+b^1 = \\left[\\begin{array}{ccc}\n",
    "1&-1&0 \\\\ 0&-1&1 \\\\ 1& 1&-1 \\\\ 1&1&1 \\end{array}\\right] \\left[\\begin{array}{c}\n",
    "1.2 \\\\ -1 \\\\ 2\\end{array}\\right] + \\left[\\begin{array}{c}\n",
    "0 \\\\ 1 \\\\ 1\\\\-1\\end{array}\\right] =  \\left[\\begin{array}{c}2.2\\\\ 4\\\\ -0.8\\\\ 1.2\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f093cbb",
   "metadata": {},
   "source": [
    "(a) $\\bar{h}^{1}(x) = W^1x+b^1 = \\left[\\begin{array}{ccc}\n",
    "1&-1&0 \\\\ 0&-1&1 \\\\ 1& 1&-1 \\\\ 1&1&1 \\end{array}\\right] \\left[\\begin{array}{c}\n",
    "1.2 \\\\ -1 \\\\ 2\\end{array}\\right] + \\left[\\begin{array}{c}\n",
    "0 \\\\ 1 \\\\ 1\\\\-1\\end{array}\\right] =  \\left[\\begin{array}{c}2.2\\\\ 4\\\\ -0.8\\\\ 1.2\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070db93",
   "metadata": {},
   "source": [
    "(c) $\\bar{h}^{2}(x) = W^2h^1+b^2 = \\left[\\begin{array}{cccc}1.5 &1 & 1 & -1\\\\0 &0 & 1 & 1\\\\-1 &1 & 1 & -1\\end{array}\\right] \\left[\\begin{array}{c}2.2\\\\4\\\\0\\\\1.2 \\end{array}\\right] + \\left[\\begin{array}{c}1 \\\\0\\\\0.5 \\end{array}\\right] = \\left[\\begin{array}{c}7.1\\\\1.2\\\\1.1 \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abe9e6",
   "metadata": {},
   "source": [
    "(d)$loss = l(y,\\hat{ y}) = {1 \\over 2}[(1.5-7.1)^2 + (-1-1.2)^2 + (2-1.1)^2] = 18.505$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817db476",
   "metadata": {},
   "source": [
    "(e)$\\frac{\\partial l}{\\partial h^{2}} = 2 \\times {1 \\over 2}(\\sum y- h^2)  =h^2-y =\\left[\\begin{array}{c}5.6\\\\2.2\\\\-0.9 \\end{array}\\right]$\n",
    "\n",
    "\n",
    "\n",
    "$\\frac{\\partial l}{\\partial W^{2}} = \\frac{\\partial l}{\\partial h^{2}} \\frac{\\partial h^2}{\\partial W^{2}} = (h^2-y)(h^1)^T = \\left[\\begin{array}{c}5.6\\\\2.2\\\\-0.9 \\end{array}\\right]\\left[\\begin{array}{c}2.2& 4& 0& 1.2\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "12.32&22.4&0&6.72\\\\ \n",
    "4.84&8.8&0&2.64\\\\\n",
    "-1.98&-3.6&0&-1.08\n",
    "\\end{array}\\right]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$\\frac{\\partial l}{\\partial b^{2}} =  \\frac{\\partial l}{\\partial h^{2}} \\frac{\\partial h^2}{\\partial b^{2}}  =h^2-y =\\left[\\begin{array}{c}5.6\\\\2.2\\\\-0.9 \\end{array}\\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0225cb",
   "metadata": {},
   "source": [
    "(f)$\\frac{\\partial l}{\\partial h^{1}} = \\frac{\\partial l}{\\partial h^{2}}\\frac{\\partial h^2}{\\partial h^{1}} =(W^2)^T(h^2-y)= g^1 =\n",
    "\\left[\\begin{array}{cccc}1.5 &1 & 1 & -1\\\\0 &0 & 1 & 1\\\\-1 &1 & 1 & -1\\end{array}\\right]^T\n",
    "\\left[\\begin{array}{c}5.6\\\\2.2\\\\-0.9 \\end{array}\\right]   \n",
    "=\\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right]$\n",
    "\n",
    "$\\frac{\\partial l}{\\partial \\bar{h}^{1}} = \\frac{\\partial l}{\\partial h^{1}}\\frac{\\partial h^1}{\\partial \\bar{h}^{1}} =diag(Relu'(\\bar h^1))^Tg^1\n",
    "=\\left[\\begin{array}{c}1&0&0&0\\\\0&1&0&0\\\\0&0&1&0\\\\0&0&0&1\\end{array}\\right] \n",
    "\\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right]\n",
    "= \\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right] $\n",
    "\n",
    "$\\frac{\\partial l}{\\partial W^{1}} = \\frac{\\partial l}{\\partial \\bar h^{1}}\\frac{\\partial \\bar h^1}{\\partial W^{1}} =g^1h^1 =  \\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right]\\left[\\begin{array}{c}1.2 & -1 & 2\\end{array}\\right] \n",
    "= \\left[\\begin{array}\n",
    "11.16&-9.3&-18.6\\\\\n",
    "5.64&-4.7&9.4\\\\ \n",
    "8.28&-6.9&13.8\\\\ \n",
    "-3&2.5&-5\\end{array}\\right]$\n",
    "\n",
    "$\\frac{\\partial l}{\\partial b^{1}} = \\frac{\\partial l}{\\partial h^{1}} \\frac{\\partial h^1}{\\partial b^{1}} =g^1 =\\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e119a3b",
   "metadata": {},
   "source": [
    "(g)$W^2 = W^2-\\eta \\frac{\\partial l}{\\partial W^{2}}= \\left[\\begin{array}{cccc}1.5 &1 & 1 & -1\\\\0 &0 & 1 & 1\\\\-1 &1 & 1 & -1\\end{array}\\right] - 0.01\\left[\\begin{array}{c}\n",
    "12.32&22.4&0&6.72\\\\ \n",
    "4.84&8.8&0&2.64\\\\\n",
    "-1.98&-3.6&0&-1.08\n",
    "\\end{array}\\right] = \\left[\\begin{array} {c}1.3768&0.776&1&-1.0672\\\\ -0.0484&-0.088&1&0.9736\\\\ -0.9802&1.036&1&-0.9892\\end{array}\\right]$\n",
    "\n",
    "$b^2 = b^2-\\eta \\frac{\\partial l}{\\partial b^{2}} =  \\left[\\begin{array}{c}1 \\\\0\\\\0.5 \\end{array}\\right] - 0.01\\left[\\begin{array}{c}5.6\\\\2.2\\\\-0.9 \\end{array}\\right]= \\left[\\begin{array} {c}0.944\\\\ -0.022\\\\ 1.509\\end{array}\\right]$\n",
    "\n",
    "$W^1 = W^1-\\eta \\frac{\\partial l}{\\partial W^{1}} = \\left[\\begin{array}{ccc}\n",
    "1&-1&0 \\\\ 0&-1&1 \\\\ 1&1&-1 \\\\ 1&1&1 \\end{array}\\right] - 0.01 \\left[\\begin{array}\n",
    "11.16&-9.3&-18.6\\\\\n",
    "5.64&-4.7&9.4\\\\ \n",
    "8.28&-6.9&13.8\\\\ \n",
    "-3&2.5&-5\\end{array}\\right] = \\left[\\begin{array}{c} 0.9884&-0.907&0.186\\\\ -0.0564&-0.953&0.906\\\\ 0.9172&1.069&-1.138\\\\ 1.03&0.975&1.05\\end{array}\\right]$\n",
    "\n",
    "$b^1 = b^1-\\eta \\frac{\\partial l}{\\partial b^{1}} = \\left[\\begin{array}{c}\n",
    "0 \\\\ 1 \\\\ 1\\\\-1\\end{array}\\right]-0.01\\left[\\begin{array}{c}9.3\\\\4.7\\\\6.9\\\\-2.5 \\end{array}\\right] = \\left[\\begin{array}{c}-0.093\\\\ 0.953\\\\ 0.931\\\\ -0.975\\end{array}\\right]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea90089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b074c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
